You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint from ../scratch/tofu_finetuned_5epoch_aya_10_lang_2e5/
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 67.74it/s]
Working on eval task eval_log with split retain_perturbed
  0%|          | 0/14 [00:00<?, ?it/s]  7%|▋         | 1/14 [00:07<01:43,  7.95s/it] 14%|█▍        | 2/14 [00:13<01:21,  6.77s/it] 21%|██▏       | 3/14 [00:19<01:08,  6.24s/it] 29%|██▊       | 4/14 [00:25<01:02,  6.21s/it] 36%|███▌      | 5/14 [00:31<00:53,  5.97s/it] 43%|████▎     | 6/14 [00:36<00:46,  5.83s/it] 50%|█████     | 7/14 [00:42<00:41,  5.95s/it] 57%|█████▋    | 8/14 [00:48<00:35,  5.90s/it] 64%|██████▍   | 9/14 [00:54<00:29,  5.84s/it] 71%|███████▏  | 10/14 [01:00<00:23,  5.83s/it] 79%|███████▊  | 11/14 [01:05<00:17,  5.69s/it] 86%|████████▌ | 12/14 [01:11<00:11,  5.85s/it] 93%|█████████▎| 13/14 [01:17<00:05,  5.76s/it]100%|██████████| 14/14 [01:23<00:00,  5.79s/it]100%|██████████| 14/14 [01:23<00:00,  5.95s/it]
[2025-09-13 13:07:17,742][absl][INFO] - Using default tokenizer.
[2025-09-13 13:07:18,260][absl][INFO] - Using default tokenizer.
0it [00:00, ?it/s]1it [00:01,  1.59s/it]2it [00:03,  1.59s/it]3it [00:04,  1.59s/it]4it [00:06,  1.58s/it]5it [00:07,  1.58s/it]6it [00:09,  1.58s/it]7it [00:11,  1.58s/it]8it [00:12,  1.58s/it]9it [00:14,  1.58s/it]10it [00:15,  1.58s/it]11it [00:17,  1.58s/it]12it [00:18,  1.58s/it]13it [00:20,  1.58s/it]14it [00:22,  1.58s/it]15it [00:23,  1.58s/it]16it [00:25,  1.58s/it]17it [00:26,  1.58s/it]18it [00:28,  1.58s/it]19it [00:30,  1.59s/it]20it [00:31,  1.59s/it]21it [00:33,  1.58s/it]22it [00:34,  1.59s/it]23it [00:36,  1.59s/it]24it [00:38,  1.59s/it]25it [00:39,  1.59s/it]26it [00:41,  1.59s/it]27it [00:42,  1.59s/it]28it [00:44,  1.59s/it]29it [00:45,  1.59s/it]30it [00:47,  1.59s/it]31it [00:49,  1.58s/it]32it [00:50,  1.58s/it]33it [00:52,  1.59s/it]34it [00:53,  1.59s/it]35it [00:55,  1.58s/it]36it [00:57,  1.59s/it]37it [00:58,  1.59s/it]38it [01:00,  1.59s/it]39it [01:01,  1.59s/it]40it [01:03,  1.59s/it]41it [01:04,  1.59s/it]42it [01:06,  1.59s/it]43it [01:08,  1.59s/it]44it [01:09,  1.58s/it]45it [01:11,  1.59s/it]46it [01:12,  1.59s/it]47it [01:14,  1.58s/it]48it [01:16,  1.59s/it]49it [01:17,  1.59s/it]50it [01:19,  1.59s/it]51it [01:20,  1.59s/it]52it [01:22,  1.59s/it]53it [01:24,  1.59s/it]54it [01:25,  1.59s/it]55it [01:27,  1.59s/it]56it [01:28,  1.59s/it]57it [01:30,  1.59s/it]58it [01:31,  1.37s/it]58it [01:31,  1.57s/it]
Working on eval task eval_real_author_wo_options with split real_authors_perturbed
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:06<00:19,  6.57s/it] 50%|█████     | 2/4 [00:12<00:11,  5.99s/it] 75%|███████▌  | 3/4 [00:17<00:05,  5.83s/it]100%|██████████| 4/4 [00:22<00:00,  5.32s/it]100%|██████████| 4/4 [00:22<00:00,  5.58s/it]
[2025-09-13 13:09:12,362][absl][INFO] - Using default tokenizer.
[2025-09-13 13:09:12,879][absl][INFO] - Using default tokenizer.
0it [00:00, ?it/s]1it [00:01,  1.30s/it]2it [00:02,  1.30s/it]3it [00:03,  1.30s/it]4it [00:05,  1.30s/it]5it [00:06,  1.30s/it]6it [00:07,  1.30s/it]7it [00:09,  1.30s/it]8it [00:10,  1.30s/it]9it [00:11,  1.30s/it]10it [00:12,  1.30s/it]11it [00:14,  1.30s/it]12it [00:15,  1.30s/it]13it [00:16,  1.30s/it]14it [00:18,  1.30s/it]15it [00:19,  1.18s/it]15it [00:19,  1.27s/it]
Working on eval task eval_real_world_wo_options with split world_facts_perturbed
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:06<00:18,  6.20s/it] 50%|█████     | 2/4 [00:12<00:12,  6.42s/it] 75%|███████▌  | 3/4 [00:17<00:05,  5.48s/it]100%|██████████| 4/4 [00:23<00:00,  5.74s/it]100%|██████████| 4/4 [00:23<00:00,  5.82s/it]
[2025-09-13 13:09:55,800][absl][INFO] - Using default tokenizer.
[2025-09-13 13:09:56,325][absl][INFO] - Using default tokenizer.
0it [00:00, ?it/s]1it [00:01,  1.30s/it]2it [00:02,  1.30s/it]3it [00:03,  1.30s/it]4it [00:05,  1.30s/it]5it [00:06,  1.30s/it]6it [00:07,  1.30s/it]7it [00:09,  1.30s/it]8it [00:10,  1.30s/it]9it [00:11,  1.30s/it]10it [00:12,  1.30s/it]11it [00:14,  1.30s/it]12it [00:15,  1.30s/it]13it [00:16,  1.30s/it]14it [00:18,  1.30s/it]15it [00:19,  1.30s/it]16it [00:20,  1.30s/it]17it [00:21,  1.25s/it]17it [00:21,  1.29s/it]
Working on eval task eval_log_forget with split forget01_perturbed
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:04<00:04,  4.72s/it]100%|██████████| 2/2 [00:10<00:00,  5.13s/it]100%|██████████| 2/2 [00:10<00:00,  5.07s/it]
[2025-09-13 13:10:28,762][absl][INFO] - Using default tokenizer.
[2025-09-13 13:10:29,200][absl][INFO] - Using default tokenizer.
0it [00:00, ?it/s]1it [00:01,  1.58s/it]2it [00:03,  1.59s/it]3it [00:04,  1.58s/it]4it [00:06,  1.58s/it]5it [00:07,  1.58s/it]6it [00:09,  1.49s/it]6it [00:09,  1.54s/it]
