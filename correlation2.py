# """
# Compute ALL lang2vec distance matrices for a set of languages in one call.
# """

# import pandas as pd
# import lang2vec.lang2vec as l2v

# # ---- Config ----
# ISO1_TO_ISO3 = {
#     "en": "eng", "fr": "fra", "ru": "rus", "ar": "arb", "ja": "jpn",
#     "fa": "fas", "hi": "hin", "ko": "kor", "he": "heb", "iw": "heb",
#     "id": "ind", "in": "ind"
# }

# langs_input = ["en", "fr", "ru", "ar", "ja", "fa", "hi", "ko", "iw", "id"]
# langs = [ISO1_TO_ISO3[x] for x in langs_input]

# # All available distances in this lang2vec version
# DISTANCE_TYPES = list(l2v.DISTANCES)

# # ---- Compute all distances in one call ----
# matrices = l2v.distance(DISTANCE_TYPES, *langs)
# # `matrices` is a list of numpy arrays in the same order as DISTANCE_TYPES

# # ---- Save results ----
# # for metric, mat in zip(DISTANCE_TYPES, matrices):
# #     df = pd.DataFrame(mat, index=langs, columns=langs)
# #     df.to_csv(f"lang2vec_{metric}_distance_matrix.csv", float_format="%.6f")
# #     print(f"Saved {metric} distances → lang2vec_{metric}_distance_matrix.csv")

# # print("\nDone.")


# print(l2v.distance(['syntactic','geographic'], 'eng', 'fra', 'fas'))






# ========= Correlations for 3 impacts × 3 distances =========
import numpy as np
from scipy.stats import pearsonr
from skbio.stats.distance import mantel, DistanceMatrix

# ---- bring back your two other distances (phonological, syntactic) ----
dist_inventory = np.array([
    [0.000000, 0.475300, 0.559400, 0.598300, 0.547200, 0.598300, 0.468400, 0.486600, 0.554900, 0.454600],
    [0.475300, 0.000000, 0.515200, 0.602500, 0.505200, 0.602500, 0.461800, 0.480400, 0.608200, 0.468800],
    [0.559400, 0.515200, 0.000000, 0.688000, 0.541200, 0.688000, 0.601500, 0.651100, 0.615600, 0.503000],
    [0.598300, 0.602500, 0.688000, 0.000000, 0.659700, 0.000000, 0.536300, 0.673700, 0.702800, 0.669000],
    [0.547200, 0.505200, 0.541200, 0.659700, 0.000000, 0.659700, 0.498000, 0.520400, 0.562000, 0.459900],
    [0.598300, 0.602500, 0.688000, 0.000000, 0.659700, 0.000000, 0.536300, 0.673700, 0.702800, 0.669000],
    [0.468400, 0.461800, 0.601500, 0.536300, 0.498000, 0.536300, 0.000000, 0.558000, 0.562900, 0.481600],
    [0.486600, 0.480400, 0.651100, 0.673700, 0.520400, 0.673700, 0.558000, 0.000000, 0.588600, 0.456900],
    [0.554900, 0.608200, 0.615600, 0.702800, 0.562000, 0.702800, 0.562900, 0.588600, 0.000000, 0.499500],
    [0.454600, 0.468800, 0.503000, 0.669000, 0.459900, 0.669000, 0.481600, 0.456900, 0.499500, 0.000000]
])

dist_phono = np.array([
    [0.000000, 0.427000, 0.280400, 0.568700, 0.503200, 0.568700, 0.343300, 0.463800, 0.568700, 0.273600],
    [0.427000, 0.000000, 0.333300, 0.545600, 0.440700, 0.545600, 0.267700, 0.580400, 0.545600, 0.427000],
    [0.280400, 0.333300, 0.000000, 0.616200, 0.432700, 0.616200, 0.204800, 0.500000, 0.616200, 0.280400],
    [0.568700, 0.545600, 0.616200, 0.000000, 0.616200, 0.000200, 0.592200, 0.641000, 0.000200, 0.568700],
    [0.503200, 0.440700, 0.432700, 0.616200, 0.000000, 0.616200, 0.471700, 0.687500, 0.616200, 0.503200],
    [0.568700, 0.545600, 0.616200, 0.000200, 0.616200, 0.000000, 0.592200, 0.641000, 0.000200, 0.568700],
    [0.343300, 0.267700, 0.204800, 0.592200, 0.471700, 0.592200, 0.000000, 0.531900, 0.592200, 0.343300],
    [0.463800, 0.580400, 0.500000, 0.641000, 0.687500, 0.641000, 0.531900, 0.000000, 0.641000, 0.463800],
    [0.568700, 0.545600, 0.616200, 0.000200, 0.616200, 0.000200, 0.592200, 0.641000, 0.000000, 0.568700],
    [0.273600, 0.427000, 0.280400, 0.568700, 0.503200, 0.568700, 0.343300, 0.463800, 0.568700, 0.000000],
])

dist_syntax = np.array([
    [0.000000, 0.460000, 0.490000, 0.670000, 0.660000, 0.570000, 0.590000, 0.620000, 0.520000, 0.520000],
    [0.460000, 0.000000, 0.510000, 0.670000, 0.710000, 0.570000, 0.580000, 0.690000, 0.470000, 0.560000],
    [0.490000, 0.510000, 0.000000, 0.670000, 0.660000, 0.570000, 0.500000, 0.560000, 0.430000, 0.610000],
    [0.670000, 0.670000, 0.670000, 0.000000, 0.870000, 0.670000, 0.740000, 0.810000, 0.600000, 0.600000],
    [0.660000, 0.710000, 0.660000, 0.870000, 0.000000, 0.590000, 0.600000, 0.400000, 0.690000, 0.760000],
    [0.570000, 0.570000, 0.570000, 0.670000, 0.590000, 0.000000, 0.580000, 0.570000, 0.540000, 0.620000],
    [0.590000, 0.580000, 0.500000, 0.740000, 0.600000, 0.580000, 0.000000, 0.470000, 0.530000, 0.670000],
    [0.620000, 0.690000, 0.560000, 0.810000, 0.400000, 0.570000, 0.470000, 0.000000, 0.660000, 0.700000],
    [0.520000, 0.470000, 0.430000, 0.600000, 0.690000, 0.540000, 0.530000, 0.660000, 0.000000, 0.540000],
    [0.520000, 0.560000, 0.610000, 0.600000, 0.760000, 0.620000, 0.670000, 0.700000, 0.540000, 0.000000],
])

impact = np.array([
    [0.00, 0.25, 0.50, 0.69, 0.63, 0.72, 0.88, 0.32, 0.66, 0.30],
    [0.33, 0.03, 0.50, 0.67, 0.72, 0.71, 0.88, 0.44, 0.67, 0.26],
    [0.46, 0.52, 0.01, 0.65, 0.68, 0.66, 0.82, 0.67, 0.66, 0.46],
    [0.69, 0.66, 0.71, 0.01, 0.81, 0.58, 0.90, 0.80, 0.70, 0.66],
    [0.70, 0.71, 0.74, 0.81, 0.00, 0.75, 0.77, 0.31, 0.78, 0.74],
    [0.68, 0.66, 0.57, 0.46, 0.71, 0.00, 0.77, 0.72, 0.63, 0.63],
    [0.80, 0.81, 0.76, 0.79, 0.61, 0.69, 0.05, 0.68, 0.83, 0.87],
    [0.29, 0.44, 0.65, 0.77, 0.38, 0.74, 0.80, 0.00, 0.80, 0.45],
    [0.64, 0.61, 0.61, 0.58, 0.73, 0.65, 0.86, 0.74, 0.01, 0.61],
    [0.34, 0.30, 0.55, 0.64, 0.73, 0.66, 0.84, 0.54, 0.60, 0.00]
])

impact1 = np.array([
    [0.00, 0.14, 0.38, 0.60, 0.55, 0.65, 0.81, 0.24, 0.56, 0.19],
    [0.12, 0.00, 0.36, 0.52, 0.64, 0.57, 0.85, 0.29, 0.54, 0.21],
    [0.20, 0.24, 0.00, 0.50, 0.41, 0.34, 0.49, 0.36, 0.36, 0.19],
    [0.49, 0.50, 0.56, 0.01, 0.68, 0.46, 0.83, 0.66, 0.56, 0.57],
    [0.44, 0.49, 0.47, 0.61, 0.00, 0.51, 0.55, 0.19, 0.57, 0.45],
    [0.57, 0.52, 0.39, 0.31, 0.54, 0.00, 0.64, 0.59, 0.47, 0.52],
    [0.72, 0.77, 0.66, 0.73, 0.51, 0.59, 0.03, 0.54, 0.72, 0.72],
    [0.12, 0.27, 0.49, 0.70, 0.30, 0.63, 0.72, 0.00, 0.68, 0.27],
    [0.27, 0.28, 0.26, 0.50, 0.52, 0.43, 0.66, 0.40, 0.00, 0.27],
    [0.06, 0.07, 0.23, 0.41, 0.47, 0.38, 0.68, 0.22, 0.39, 0.00]
])


impact2 = np.array([
    [0.26, 0.71, 0.84, 0.92, 0.90, 0.95, 0.98, 0.74, 0.88, 0.80],
    [0.72, 0.35, 0.83, 0.90, 0.91, 0.91, 0.98, 0.78, 0.88, 0.77],
    [0.85, 0.88, 0.26, 0.93, 0.95, 0.92, 0.97, 0.93, 0.92, 0.89],
    [0.93, 0.92, 0.95, 0.29, 0.97, 0.90, 0.99, 0.97, 0.93, 0.93],
    [0.95, 0.95, 0.95, 0.97, 0.28, 0.96, 0.96, 0.85, 0.97, 0.96],
    [0.93, 0.91, 0.91, 0.87, 0.95, 0.25, 0.97, 0.96, 0.92, 0.90],
    [0.95, 0.97, 0.94, 0.94, 0.90, 0.92, 0.57, 0.91, 0.97, 0.98],
    [0.85, 0.87, 0.92, 0.97, 0.83, 0.96, 0.97, 0.28, 0.97, 0.89],
    [0.90, 0.89, 0.90, 0.91, 0.97, 0.92, 0.98, 0.95, 0.28, 0.89],
    [0.82, 0.80, 0.90, 0.93, 0.95, 0.94, 0.98, 0.89, 0.92, 0.31]
])


import numpy as np
from scipy.stats import pearsonr

# helper: flatten full matrix without diagonal
def _flat_nodiag(m):
    mask = ~np.eye(m.shape[0], dtype=bool)   # mask excludes diagonal
    return m[mask]

# ---- pack inputs ----
distances = {
    "Inventory": dist_inventory,
    "Phonological": dist_phono,
    "Syntactic": dist_syntax,
}
impacts = {
    "impact": impact,
    "impact1": impact1,
    "impact2": impact2,
}

# ---- Pearson (full matrices without diagonal) ----
print("\n=== Pearson correlations (no symmetrization, no diagonal) ===")
header = ["Distance/Impact"] + list(impacts.keys())
print("{:14s}  ".format(header[0]) + "  ".join("{:>9s}".format(h) for h in header[1:]))

for d_name, D in distances.items():
    ## Without Diagonal
    # d_vec = _flat_nodiag(D)
    # print(D.shape)
    
    ## With Full Matrix
    d_vec = D.flatten().tolist()
    row = [d_name]
    for i_name, I in impacts.items():
        ## Without Diagonal
        # i_vec = _flat_nodiag(I)
        ## With Full Matrix
        i_vec = I.flatten().tolist()
        r, p = pearsonr(d_vec, i_vec)
        row.append(f"{r:9.3f}")
    print("{:14s}  ".format(row[0]) + "  ".join(row[1:]))

print("\n=== Pearson p-values (no symmetrization, no diagonal) ===")
print("{:14s}  ".format(header[0]) + "  ".join("{:>9s}".format(h) for h in header[1:]))
for d_name, D in distances.items():
    d_vec = _flat_nodiag(D)
    row = [d_name]
    for i_name, I in impacts.items():
        r, p = pearsonr(d_vec, _flat_nodiag(I))
        row.append(f"{p:9.3g}")
    print("{:14s}  ".format(row[0]) + "  ".join(row[1:]))
